{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edc0160",
   "metadata": {},
   "source": [
    "# Understanding and Visualizing Data with Python\n",
    "\n",
    "## Week 1\n",
    "\n",
    "### Variable Types\n",
    "* Quantitative Variables\n",
    "    * Continuous\n",
    "    * Discrete\n",
    "* Categorical (or Qualitative) Variables\n",
    "    * Ordinal - groups have an order or ranking\n",
    "    * Nominal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c97ce",
   "metadata": {},
   "source": [
    "## Week 2\n",
    "\n",
    "### Quantitative data\n",
    "* Histograms\n",
    "    - Shape: right-skewed (tails on the right)\n",
    "    - Center\n",
    "    - Spread\n",
    "    - Outliers\n",
    "* Numerical Summaries (Summary Statistics)\n",
    "    - 5 Number Summary\n",
    "        * Min\n",
    "        * 1st Quartile (25%, Q1)\n",
    "        * Median (50%)\n",
    "        * 3rdd Quartile (75%, Q3)\n",
    "        * Max <br>\n",
    "        Others: <br>\n",
    "        IQR = Q3 - Q1 (Inter Quartile Range) <br>\n",
    "        Range = Max - Min\n",
    "    - Left skewed histogram: mean is **less than** mediam since there are outliers on the left.\n",
    "    - Range is not robust to outliers. IQR is robust to outliers.\n",
    "    - Standard deviation: roughly the average distance of the values from their mean.\n",
    "* Imperical Rule\n",
    "    - ($\\mu-\\sigma$, $\\mu+\\sigma$): 68%\n",
    "    - ($\\mu-2\\sigma$, $\\mu+2\\sigma$): 95%\n",
    "    - ($\\mu-3\\sigma$, $\\mu+3\\sigma$): 99.7%\n",
    "    _ standardize: z-score=(Obs-mean)/SD\n",
    "* Boxplots\n",
    "    - 5 Number Summary\n",
    "    - con: Boxplots can help identify outliers.\n",
    "    - pro: Boxplots can hide gaps and clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a601e080",
   "metadata": {},
   "source": [
    "## Week 3\n",
    "### Multivariate Data\n",
    "* Multivariate Categorical Data\n",
    "    - Histogram\n",
    "    - Boxplot\n",
    "\n",
    "* Multivariate Quantitative Data\n",
    "    - Scatterplot\n",
    "        * `Pearson correlation` (R or $\\rho$): between -1 and 1 indicating the strength and direction of relationship between two variables. \n",
    "        * **Correlation Does Not Imply Causation**.\n",
    "        * Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7240ee33",
   "metadata": {},
   "source": [
    "## Week 4\n",
    "### Populations vs. Samples\n",
    "Well-defined target population \n",
    "#### Probability Sampling\n",
    "    1. Simple Random Sampling (SRS)\n",
    "        * randomly select n units from N population units\n",
    "        * equal probability of selection = n/N\n",
    "        * all possible samples of size n are equally likely\n",
    "        * estimates are unbiased on average\n",
    "        * can be **with replacement** or **without replacement**\n",
    "        * for both: probability of selection = n/N\n",
    "        * SRS is rarely used in practice: too expensive\n",
    "    2. Complex Sampling for Larger Populations\n",
    "        * stratums: stratification\n",
    "        * clusters\n",
    "        * simple random sampling within each cluster\n",
    "#### Non-Probability Sampling <br>\n",
    "1. Properties\n",
    "    * **Probabilities of selection cannot be determined for sampled units**\n",
    "    * no random selection\n",
    "    * clusters are not randomly selected\n",
    "    * not expensive compared to SRS\n",
    "2. Examples\n",
    "    * volunteers\n",
    "    * opt-in web surveys\n",
    "    * snowball sampling\n",
    "    * convenience samples\n",
    "    * quota samples\n",
    "3. Cons\n",
    "    * strong risk of sampling bias\n",
    "    * no statistical basis for making inference\n",
    "4. What can we do?\n",
    "    * Pseudo-Randomization Approach\n",
    "        - combine non-probability sample with a probabilitiy sample\n",
    "        - estimate probability of being included in non-probability sample\n",
    "        - treat estimated probabilities of selection as \"known\" for non-probability sample\n",
    "    * Calibration Approach\n",
    "        - compute weights for responding units in non-probability sample that allow weightedd sampled to mirror a known population\n",
    "        - downweight/upweight\n",
    "        - limitation: if weighting factor not related to variables of interest -> will not reduce bias\n",
    "\n",
    "### Probability Samples\n",
    "#### Probability Samples -> Sampling Distributions\n",
    "* Sampling Distributions\n",
    "    - distribution of survey estimates we would see if we selected many random samples using same sampling design and computed an estimate from each.\n",
    "    - key properties:\n",
    "        * hypothetical\n",
    "        * large sample size -> normal distribution (**Central Limit Theorem**)\n",
    "* Sampling Variance\n",
    "    - variability in the estimates described by the sampling distribution\n",
    "    - sampling errors randomly vary\n",
    "    - variability of these sampling errors describes the variance of the sampling distribution\n",
    "    - larger samples -> less sampling variance\n",
    "* Why is Sampling Variance Important?\n",
    "    - sampling theory allows us to estimate the variancee of sampling distribution based on **only one sample**\n",
    "* Sampling Distributions of Other Common Statistics\n",
    "    - (**Central Limit Theorem**) <span style='color:maroon'>Given large enough samples, sampling distributions of most statistics of interest tend to normality (regardless of how the input variables are distributed)</span>.\n",
    "    - Pearson Correlations: between -1 and 1. \n",
    "    - Non-Normal Sampling Distributions\n",
    "        * **Not all** statistics have normal sampling distributions\n",
    "        * In these cases, more specialized procedures needed to make population inferences (e.g., Bayesian methods).\n",
    "\n",
    "\n",
    "### Inference in Practice\n",
    "#### Making Population Inference Based on Only One Probability Sample\n",
    "Key Assumption: Normality (sampling distribution of statistics is normal *if the sample size is large*)\n",
    "1. Confidence Interval Estimate for Parameters of Interest\n",
    "    - To form a confidence interval: best estimates +/- margin of error\n",
    "    - 95% confidence interval: **expect 95% of intervals will cover true population value**\n",
    "2. Hypothesis Testing about Parameters of Interest\n",
    "These two inferential procedures are valid if **probability sampling** was used.\n",
    "\n",
    "#### Inference for Non-Probability Samples\n",
    "Non-probability samples do not let us rely on sampling theory for making population inferences based on expected sampling distributions. <br>\n",
    "For any of th following estimation techniques for non-probability samples, we need to have common variables in the two data sets. \n",
    "1. Quasi-Randomization (or pseudo-randomization)\n",
    "    * combine non-probability sample with prior data from a probablity sample that collect the same features\n",
    "    * stack the two datasets\n",
    "    * code: if member of non-probability sample, label as 1; if member of probability sample, label as 0\n",
    "    * fit **logistic regression model**: predict label with common variables\n",
    "        - weighting non-probability cases by 1\n",
    "        - weighting probability cases by their survey weights \n",
    "    * big idea: \n",
    "        1. can predict probability of being in non-probability sample\n",
    "        2. invert predicted probabilities for non-probability samples, treat as survey weight (i.e., inverse of probability of being selected)\n",
    "    * issue: how to estimate sampling variance?\n",
    "        - not clear yet: replication method\n",
    "    \n",
    "2. Population Modeling\n",
    "    * Big idea: use predictive modeling to predict aggregate sample quantities (usually totals) on key variables of interest for population units not included in the non-probability sample\n",
    "    * compute estimates of interest using estimated totals <br>\n",
    "In summary, \n",
    "* leverage other auxiliary information\n",
    "* predict values\n",
    "\n",
    "\n",
    "#### Complex Samples\n",
    "Complex samples: any probability sample where design involves more than Simple Random Sampling (SRS). <br>\n",
    "Features of complex samples: stratification. aim -> choose sample scheme to reduce sampling variance. <br>\n",
    "Proportion Allocation\n",
    "* Features of Complex Samples\n",
    "    - Stratification: eliminate between stratum variance in means (or total) on variable from the sampling variance\n",
    "        * count for stratification in analysis -> conservative; large confidence intervals\n",
    "    - Clustering: random sampling of larger clusters of population elements, possibly across multiple stages\n",
    "        * reduce cost of data collection -> inference too liberal, confidence intervals too narrow\n",
    "    - Weighting: complex samples are still probability samples\n",
    "        * unequal probabilities of selection for different units \n",
    "        * weights = inverse of probability of selection\n",
    "            - If my probability is 1/100 -> my weight is 100\n",
    "            - I represent myself and 99 others in the population\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_mac",
   "language": "python",
   "name": "ml_mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
